{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "The objective of this task is to predict keypoint positions on face images. This can be used as a building block in several applications, such as:\n",
    "\n",
    "    tracking faces in images and video\n",
    "    analysing facial expressions\n",
    "    detecting dysmorphic facial signs for medical diagnosis\n",
    "    biometrics / face recognition\n",
    "\n",
    "Detecing facial keypoints is a very challenging problem.  Facial features vary greatly from one individual to another, and even for a single individual, there is a large amount of variation due to 3D pose, size, position, viewing angle, and illumination conditions. Computer vision research has come a long way in addressing these difficulties, but there remain many opportunities for improvement.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Root Mean Squared Error (RMSE)\n",
    "\n",
    "Submissions are scored on the root mean squared error. RMSE is very common and is a suitable general-purpose error metric. Compared to the Mean Absolute Error, RMSE punishes large errors:\n",
    "\n",
    "RMSE=1n∑i=1n(yi−y^i)2−−−−−−−−−−−−√,\n",
    "\n",
    "where y hat is the predicted value and y is the original value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Description\n",
    "Each predicted keypoint is specified by an (x,y) real-valued pair in the space of pixel indices. There are 15 keypoints, which represent the following elements of the face:\n",
    "\n",
    "left_eye_center, right_eye_center, left_eye_inner_corner, left_eye_outer_corner, right_eye_inner_corner, right_eye_outer_corner, left_eyebrow_inner_end, left_eyebrow_outer_end, right_eyebrow_inner_end, right_eyebrow_outer_end, nose_tip, mouth_left_corner, mouth_right_corner, mouth_center_top_lip, mouth_center_bottom_lip\n",
    "\n",
    "Left and right here refers to the point of view of the subject.\n",
    "\n",
    "In some examples, some of the target keypoint positions are misssing (encoded as missing entries in the csv, i.e., with nothing between two commas).\n",
    "\n",
    "The input image is given in the last field of the data files, and consists of a list of pixels (ordered by row), as integers in (0,255). The images are 96x96 pixels.\n",
    "\n",
    "Data files\n",
    "\n",
    "    training.csv: list of training 7049 images. Each row contains the (x,y) coordinates for 15 keypoints, and image data as row-ordered list of pixels.\n",
    "    test.csv: list of 1783 test images. Each row contains ImageId and image data as row-ordered list of pixels\n",
    "    submissionFileFormat.csv: list of 27124 keypoints to predict. Each row contains a RowId, ImageId, FeatureName, Location. FeatureName are \"left_eye_center_x,\" \"right_eyebrow_outer_end_y,\" etc. Location is what you need to predict. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "import numbers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train examples:7049\n",
      "the shape of train_df7049x31\n",
      "Number of test examples:1783\n",
      "the shape of test_df1783x2\n",
      "----------------train----dropna():-------------------\n",
      "Number of train examples:2140\n",
      "the shape of train_df2140x31\n",
      "----------------test----dropna():-------------------\n",
      "Number of test examples:1783\n",
      "the shape of tesr_df1783x2\n"
     ]
    }
   ],
   "source": [
    "train_df=pd.read_csv('../data/facial/training.csv')\n",
    "test_df=pd.read_csv('../data/facial/test.csv')\n",
    "\n",
    "\n",
    "num_train=len(train_df)\n",
    "print(\"Number of train examples:{0}\".format(num_train))\n",
    "print(\"the shape of train_df{0}x{1}\".format(train_df.shape[0],train_df.shape[1]))\n",
    "\n",
    "num_test=len(test_df)\n",
    "print(\"Number of test examples:{0}\".format(num_test))\n",
    "print(\"the shape of test_df{0}x{1}\".format(test_df.shape[0],test_df.shape[1]))\n",
    "\n",
    "\n",
    "#去掉NAN行\n",
    "print(\"----------------train----dropna():-------------------\")\n",
    "train_df.dropna(axis=0, how='any', inplace=True)\n",
    "print(\"Number of train examples:{0}\".format(len(train_df)))\n",
    "print(\"the shape of train_df{0}x{1}\".format(train_df.shape[0],train_df.shape[1]))\n",
    "\n",
    "\n",
    "print(\"----------------test----dropna():-------------------\")\n",
    "test_df.dropna(axis=0, how='any', inplace=True)\n",
    "print(\"Number of test examples:{0}\".format(len(test_df)))\n",
    "print(\"the shape of tesr_df{0}x{1}\".format(test_df.shape[0],test_df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_eye_center_x</th>\n",
       "      <th>left_eye_center_y</th>\n",
       "      <th>right_eye_center_x</th>\n",
       "      <th>right_eye_center_y</th>\n",
       "      <th>left_eye_inner_corner_x</th>\n",
       "      <th>left_eye_inner_corner_y</th>\n",
       "      <th>left_eye_outer_corner_x</th>\n",
       "      <th>left_eye_outer_corner_y</th>\n",
       "      <th>right_eye_inner_corner_x</th>\n",
       "      <th>right_eye_inner_corner_y</th>\n",
       "      <th>...</th>\n",
       "      <th>nose_tip_y</th>\n",
       "      <th>mouth_left_corner_x</th>\n",
       "      <th>mouth_left_corner_y</th>\n",
       "      <th>mouth_right_corner_x</th>\n",
       "      <th>mouth_right_corner_y</th>\n",
       "      <th>mouth_center_top_lip_x</th>\n",
       "      <th>mouth_center_top_lip_y</th>\n",
       "      <th>mouth_center_bottom_lip_x</th>\n",
       "      <th>mouth_center_bottom_lip_y</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66.033564</td>\n",
       "      <td>39.002274</td>\n",
       "      <td>30.227008</td>\n",
       "      <td>36.421678</td>\n",
       "      <td>59.582075</td>\n",
       "      <td>39.647423</td>\n",
       "      <td>73.130346</td>\n",
       "      <td>39.969997</td>\n",
       "      <td>36.356571</td>\n",
       "      <td>37.389402</td>\n",
       "      <td>...</td>\n",
       "      <td>57.066803</td>\n",
       "      <td>61.195308</td>\n",
       "      <td>79.970165</td>\n",
       "      <td>28.614496</td>\n",
       "      <td>77.388992</td>\n",
       "      <td>43.312602</td>\n",
       "      <td>72.935459</td>\n",
       "      <td>43.130707</td>\n",
       "      <td>84.485774</td>\n",
       "      <td>238 236 237 238 240 240 239 241 241 243 240 23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64.332936</td>\n",
       "      <td>34.970077</td>\n",
       "      <td>29.949277</td>\n",
       "      <td>33.448715</td>\n",
       "      <td>58.856170</td>\n",
       "      <td>35.274349</td>\n",
       "      <td>70.722723</td>\n",
       "      <td>36.187166</td>\n",
       "      <td>36.034723</td>\n",
       "      <td>34.361532</td>\n",
       "      <td>...</td>\n",
       "      <td>55.660936</td>\n",
       "      <td>56.421447</td>\n",
       "      <td>76.352000</td>\n",
       "      <td>35.122383</td>\n",
       "      <td>76.047660</td>\n",
       "      <td>46.684596</td>\n",
       "      <td>70.266553</td>\n",
       "      <td>45.467915</td>\n",
       "      <td>85.480170</td>\n",
       "      <td>219 215 204 196 204 211 212 200 180 168 178 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.057053</td>\n",
       "      <td>34.909642</td>\n",
       "      <td>30.903789</td>\n",
       "      <td>34.909642</td>\n",
       "      <td>59.412000</td>\n",
       "      <td>36.320968</td>\n",
       "      <td>70.984421</td>\n",
       "      <td>36.320968</td>\n",
       "      <td>37.678105</td>\n",
       "      <td>36.320968</td>\n",
       "      <td>...</td>\n",
       "      <td>53.538947</td>\n",
       "      <td>60.822947</td>\n",
       "      <td>73.014316</td>\n",
       "      <td>33.726316</td>\n",
       "      <td>72.732000</td>\n",
       "      <td>47.274947</td>\n",
       "      <td>70.191789</td>\n",
       "      <td>47.274947</td>\n",
       "      <td>78.659368</td>\n",
       "      <td>144 142 159 180 188 188 184 180 167 132 84 59 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65.225739</td>\n",
       "      <td>37.261774</td>\n",
       "      <td>32.023096</td>\n",
       "      <td>37.261774</td>\n",
       "      <td>60.003339</td>\n",
       "      <td>39.127179</td>\n",
       "      <td>72.314713</td>\n",
       "      <td>38.380967</td>\n",
       "      <td>37.618643</td>\n",
       "      <td>38.754115</td>\n",
       "      <td>...</td>\n",
       "      <td>54.166539</td>\n",
       "      <td>65.598887</td>\n",
       "      <td>72.703722</td>\n",
       "      <td>37.245496</td>\n",
       "      <td>74.195478</td>\n",
       "      <td>50.303165</td>\n",
       "      <td>70.091687</td>\n",
       "      <td>51.561183</td>\n",
       "      <td>78.268383</td>\n",
       "      <td>193 192 193 194 194 194 193 192 168 111 50 12 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.725301</td>\n",
       "      <td>39.621261</td>\n",
       "      <td>32.244810</td>\n",
       "      <td>38.042032</td>\n",
       "      <td>58.565890</td>\n",
       "      <td>39.621261</td>\n",
       "      <td>72.515926</td>\n",
       "      <td>39.884466</td>\n",
       "      <td>36.982380</td>\n",
       "      <td>39.094852</td>\n",
       "      <td>...</td>\n",
       "      <td>64.889521</td>\n",
       "      <td>60.671411</td>\n",
       "      <td>77.523239</td>\n",
       "      <td>31.191755</td>\n",
       "      <td>76.997301</td>\n",
       "      <td>44.962748</td>\n",
       "      <td>73.707387</td>\n",
       "      <td>44.227141</td>\n",
       "      <td>86.871166</td>\n",
       "      <td>147 148 160 196 215 214 216 217 219 220 206 18...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   left_eye_center_x  left_eye_center_y  right_eye_center_x  \\\n",
       "0          66.033564          39.002274           30.227008   \n",
       "1          64.332936          34.970077           29.949277   \n",
       "2          65.057053          34.909642           30.903789   \n",
       "3          65.225739          37.261774           32.023096   \n",
       "4          66.725301          39.621261           32.244810   \n",
       "\n",
       "   right_eye_center_y  left_eye_inner_corner_x  left_eye_inner_corner_y  \\\n",
       "0           36.421678                59.582075                39.647423   \n",
       "1           33.448715                58.856170                35.274349   \n",
       "2           34.909642                59.412000                36.320968   \n",
       "3           37.261774                60.003339                39.127179   \n",
       "4           38.042032                58.565890                39.621261   \n",
       "\n",
       "   left_eye_outer_corner_x  left_eye_outer_corner_y  right_eye_inner_corner_x  \\\n",
       "0                73.130346                39.969997                 36.356571   \n",
       "1                70.722723                36.187166                 36.034723   \n",
       "2                70.984421                36.320968                 37.678105   \n",
       "3                72.314713                38.380967                 37.618643   \n",
       "4                72.515926                39.884466                 36.982380   \n",
       "\n",
       "   right_eye_inner_corner_y  \\\n",
       "0                 37.389402   \n",
       "1                 34.361532   \n",
       "2                 36.320968   \n",
       "3                 38.754115   \n",
       "4                 39.094852   \n",
       "\n",
       "                         ...                          nose_tip_y  \\\n",
       "0                        ...                           57.066803   \n",
       "1                        ...                           55.660936   \n",
       "2                        ...                           53.538947   \n",
       "3                        ...                           54.166539   \n",
       "4                        ...                           64.889521   \n",
       "\n",
       "   mouth_left_corner_x  mouth_left_corner_y  mouth_right_corner_x  \\\n",
       "0            61.195308            79.970165             28.614496   \n",
       "1            56.421447            76.352000             35.122383   \n",
       "2            60.822947            73.014316             33.726316   \n",
       "3            65.598887            72.703722             37.245496   \n",
       "4            60.671411            77.523239             31.191755   \n",
       "\n",
       "   mouth_right_corner_y  mouth_center_top_lip_x  mouth_center_top_lip_y  \\\n",
       "0             77.388992               43.312602               72.935459   \n",
       "1             76.047660               46.684596               70.266553   \n",
       "2             72.732000               47.274947               70.191789   \n",
       "3             74.195478               50.303165               70.091687   \n",
       "4             76.997301               44.962748               73.707387   \n",
       "\n",
       "   mouth_center_bottom_lip_x  mouth_center_bottom_lip_y  \\\n",
       "0                  43.130707                  84.485774   \n",
       "1                  45.467915                  85.480170   \n",
       "2                  47.274947                  78.659368   \n",
       "3                  51.561183                  78.268383   \n",
       "4                  44.227141                  86.871166   \n",
       "\n",
       "                                               Image  \n",
       "0  238 236 237 238 240 240 239 241 241 243 240 23...  \n",
       "1  219 215 204 196 204 211 212 200 180 168 178 19...  \n",
       "2  144 142 159 180 188 188 184 180 167 132 84 59 ...  \n",
       "3  193 192 193 194 194 194 193 192 168 111 50 12 ...  \n",
       "4  147 148 160 196 215 214 216 217 219 220 206 18...  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>182 183 182 182 180 180 176 169 156 137 124 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>76 87 81 72 65 59 64 76 69 42 31 38 49 58 58 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>177 176 174 170 169 169 168 166 166 166 161 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>176 174 174 175 174 174 176 176 175 171 165 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50 47 44 101 144 149 120 58 48 42 35 35 37 39 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId                                              Image\n",
       "0        1  182 183 182 182 180 180 176 169 156 137 124 10...\n",
       "1        2  76 87 81 72 65 59 64 76 69 42 31 38 49 58 58 4...\n",
       "2        3  177 176 174 170 169 169 168 166 166 166 161 14...\n",
       "3        4  176 174 174 175 174 174 176 176 175 171 165 15...\n",
       "4        5  50 47 44 101 144 149 120 58 48 42 35 35 37 39 ..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2140"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Image'] = train_df['Image'].apply(lambda im: np.fromstring(im, sep=' '))\n",
    "len(train_df['Image'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2140, 30)\n",
      "(2140, 9216)\n"
     ]
    }
   ],
   "source": [
    "#for label\n",
    "y_train=train_df[train_df.columns[:-1]].values\n",
    "print(y_train.shape)\n",
    "\n",
    "#for image pixel\n",
    "\n",
    "X_train=np.vstack(train_df['Image'].values) \n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1783"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Image'] = test_df['Image'].apply(lambda im: np.fromstring(im, sep=' '))\n",
    "len(test_df['Image'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1783, 9216)\n"
     ]
    }
   ],
   "source": [
    "#for test image pixel\n",
    "\n",
    "X_test=np.vstack(test_df['Image'].values) \n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class facial_data(Dataset):\n",
    "    def __init__(self,file_path,transform=None,train=True,test=False):\n",
    "        \n",
    "        self.test=test  \n",
    "        df=pd.read_csv(file_path)\n",
    "        #去掉Nan行\n",
    "        df.dropna(axis=0, how='any', inplace=True)\n",
    "        #处理Image栏\n",
    "        df['Image'] = df['Image'].apply(lambda im: np.fromstring(im, sep=' '))\n",
    "        \n",
    "        imgs_num=len(df)\n",
    "        \n",
    "        self.X=np.vstack(df['Image'].values) /255.\n",
    "        self.X = self.X.astype(np.float32)\n",
    "        \n",
    "        if self.test:\n",
    "            #self.X=np.vstack(df['Image'].values) \n",
    "            self.y=None\n",
    "        else:\n",
    "            #self.X=np.vstack(df['Image'].values) \n",
    "            self.y=train_df[train_df.columns[:-1]].values\n",
    "            self.y=(self.y-48)/48\n",
    "            self.y =self. y.astype(np.float32)\n",
    "        print(\"self.X\",self.X.shape)\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        if self.y is not None:\n",
    "            return self.X[idx],self.y[idx]\n",
    "        else:\n",
    "            return self.X[idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.X (2140, 9216)\n",
      "self.X (1783, 9216)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataset = facial_data('../data/facial/training.csv', transform=None,train=True,test=False)\n",
    "test_dataset = facial_data('../data/facial/test.csv',transform=None,train=False,test=True)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        \n",
    "        self.features=nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            nn.Conv2d(32,64,kernel_size=2,stride=1,padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            nn.Conv2d(64,128,kernel_size=2,stride=1,padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        )\n",
    "        \n",
    "        self.detection=nn.Sequential(\n",
    "            nn.Linear(15488,1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(1024,1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024,30)\n",
    "        )\n",
    "        for m in self.features.children():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            \n",
    "        \n",
    "        for m in self.detection.children():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform(m.weight)\n",
    "  \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.features(x)\n",
    "        x=x.view(x.size(0),-1)\n",
    "        x=self.detection(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Net()\n",
    "\n",
    "optimizer=optim.SGD(model.parameters(), lr=0.003,momentum=0.9)\n",
    "\n",
    "criterion=nn.MSELoss()\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    exp_lr_scheduler.step()\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (batch_idx + 1)% 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, (batch_idx + 1) * len(data), len(train_loader.dataset),\n",
    "                100. * (batch_idx + 1) / len(train_loader), loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 4D tensor as input, got 2D tensor instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-b888f18a64ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-41-da9b3cbd3341>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-148f6d326021>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 277\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, weight, bias, stride, padding, dilation, groups)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \"\"\"\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expected 4D tensor as input, got {}D tensor instead.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     f = _ConvNd(_pair(stride), _pair(padding), _pair(dilation), False,\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 4D tensor as input, got 2D tensor instead."
     ]
    }
   ],
   "source": [
    "train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
